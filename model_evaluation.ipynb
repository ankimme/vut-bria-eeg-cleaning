{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from dataloader import create_dataloader\n",
    "from enums import NoiseTypeEnum\n",
    "from model_factory import ModelFactory\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_loss_history(model_name: str, path: str, skip: int = 10):\n",
    "    \"\"\"Prints loss history from pickle file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model_name : str\n",
    "        Name of model.\n",
    "    path : str\n",
    "        Path to pickle file.\n",
    "    skip : int, optional\n",
    "        Number of epochs to skip, by default 10\n",
    "    \"\"\"\n",
    "    loss_history = pickle.load(open(path, \"rb\"))\n",
    "\n",
    "    print(f\"Final loss (train): {loss_history['train'][-1]:.2f}\")\n",
    "    print(f\"Final loss (test): {loss_history['test'][-1]:.2f}\")\n",
    "\n",
    "    fig, axs = plt.subplots(2,1, figsize=(15, 5))\n",
    "    axs[0].set_title(f\"Loss history: {model_name}\")\n",
    "    axs[0].plot(loss_history[\"train\"])\n",
    "    axs[0].plot(loss_history[\"test\"])\n",
    "    axs[0].set_xlim([0, len(loss_history[\"train\"])])\n",
    "    axs[0].legend([\"train\", \"test\"])\n",
    "\n",
    "    axs[1].set_title(f\"Loss history: {model_name} (without start)\")\n",
    "    axs[1].plot(loss_history[\"train\"])\n",
    "    axs[1].plot(loss_history[\"test\"])\n",
    "    axs[1].set_xlim(\n",
    "        [10, len(loss_history[\"train\"])]\n",
    "    )  # show only elements after 10th epoch\n",
    "    axs[1].set_ylim([0, 360])\n",
    "    axs[1].legend([\"train\", \"test\"])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def calculate_stats_on_test_data(model: torch.nn.Module, noise_type: NoiseTypeEnum, cnn=False):\n",
    "    \"\"\"Calculates R2, MAE, MSE and RMSE on test data.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        Model.\n",
    "    noise_type : NoiseTypeEnum\n",
    "        Type of noise to evaluate.\n",
    "    cnn : bool, optional\n",
    "        Whether the model is CNN or not, by default False\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    avg_r2 = 0\n",
    "    avg_mae = 0\n",
    "    avg_mse = 0\n",
    "    avg_rmse = 0\n",
    "\n",
    "    if cnn:\n",
    "        _, dl_test = create_dataloader(1, [noise_type])\n",
    "    else:\n",
    "        _, dl_test = create_dataloader(None, [noise_type])\n",
    "\n",
    "    for combined, clean in dl_test:\n",
    "        prediction = model(combined).detach().numpy()\n",
    "        gt = clean.detach().numpy()\n",
    "        if cnn:\n",
    "            prediction = prediction[0]\n",
    "            gt = gt[0]\n",
    "        r2 = r2_score(gt, prediction)\n",
    "        avg_r2 += r2\n",
    "\n",
    "        # Calculate the MAE\n",
    "        mae = np.mean(np.abs(gt - prediction))\n",
    "        avg_mae += mae\n",
    "\n",
    "        # Calculate the MSE\n",
    "        mse = mean_squared_error(gt, prediction)\n",
    "        avg_mse += mse\n",
    "\n",
    "        # Calculate the RMSE\n",
    "        rmse = np.sqrt(mse)\n",
    "        avg_rmse += rmse\n",
    "\n",
    "    avg_r2 /= len(dl_test)\n",
    "    avg_mae /= len(dl_test)\n",
    "    avg_mse /= len(dl_test)\n",
    "    avg_rmse /= len(dl_test)\n",
    "\n",
    "    print(f\"Noise: {noise_type.name}\")\n",
    "    print(f\"R2: {avg_r2:.2f}\")\n",
    "    print(f\"MAE: {avg_mae:.2f}\")\n",
    "    print(f\"MSE: {avg_mse:.2f}\")\n",
    "    print(f\"RMSE: {avg_rmse:.2f}\")\n",
    "\n",
    "\n",
    "def compare_prediction(model: torch.nn.Module, combined: np.ndarray, clean: np.ndarray, cnn=False):\n",
    "    \"\"\"Plots comparison of prediction with ground truth.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        Model.\n",
    "    combined : np.ndarray\n",
    "        Combined noisy signal.\n",
    "    clean : np.ndarray\n",
    "        Clean signal.\n",
    "    cnn : bool, optional\n",
    "        Whether the model is CNN or not, by default False\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    if cnn:\n",
    "        x = combined.unsqueeze(0)\n",
    "        prediction = model(x).detach().numpy()\n",
    "        prediction = prediction[0]\n",
    "    else: \n",
    "        prediction = model(combined).detach().numpy()\n",
    "\n",
    "    plt.plot(combined)\n",
    "    plt.plot(clean)\n",
    "    plt.plot(prediction)\n",
    "    plt.legend([\"combined\", \"clean\", \"prediction\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare test data\n",
    "Here you can generate whatever noise you want. Then just run the successive cells and the plot will update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dl_test = create_dataloader(None, [NoiseTypeEnum.EOG])\n",
    "\n",
    "combined, clean = next(iter(dl_test))\n",
    "combined.shape\n",
    "plt.plot(combined)\n",
    "plt.plot(clean)\n",
    "plt.legend(['combined', 'clean'])\n",
    "plt.title(\"Noisy data for comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCNN 01  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_loss_history(\"FCNN 1\", \"results/FCNN_01_both/loss_history/loss_history_499.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fcnn_01 = ModelFactory.FCNN_01()\n",
    "model_fcnn_01.load_state_dict( torch.load('results/FCNN_01_both/model/epoch_120.pth'))\n",
    "calculate_stats_on_test_data(model_fcnn_01, NoiseTypeEnum.EOG)\n",
    "calculate_stats_on_test_data(model_fcnn_01, NoiseTypeEnum.EMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_prediction(model_fcnn_01, combined, clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FCNN 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_loss_history(\"FCNN 02\", \"results/FCNN_02_both/loss_history/loss_history_1199.pickle\", skip = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fcnn_02 = ModelFactory.FCNN_02()\n",
    "model_fcnn_02.load_state_dict( torch.load('results/FCNN_02_both/model/epoch_900.pth'))\n",
    "calculate_stats_on_test_data(model_fcnn_02, NoiseTypeEnum.EOG)\n",
    "calculate_stats_on_test_data(model_fcnn_02, NoiseTypeEnum.EMG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_loss_history(\"LSTM\", \"results/LSTM_01/loss_history/loss_history_500.pickle\", skip=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm = ModelFactory.LSTM_01()\n",
    "model_lstm.load_state_dict(torch.load('results/LSTM_01/model/epoch_500.pth'))\n",
    "calculate_stats_on_test_data(model_lstm, NoiseTypeEnum.EOG, cnn=True)\n",
    "calculate_stats_on_test_data(model_lstm, NoiseTypeEnum.EMG, cnn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_loss_history(\"CNN 01\", \"results/CNN_01_both/loss_history/loss_history_1200.pickle\", skip=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_01 = ModelFactory.CNN_01()\n",
    "model_cnn_01.load_state_dict( torch.load('results/CNN_01_both/model/epoch_1200.pth'))\n",
    "calculate_stats_on_test_data(model_cnn_01, NoiseTypeEnum.EOG, cnn=True)\n",
    "calculate_stats_on_test_data(model_cnn_01, NoiseTypeEnum.EMG, cnn=True)\n",
    "# combined.shape\n",
    "# prediction = model(combined).detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_prediction(model_cnn_01, combined, clean, cnn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_loss_history(\"CNN 02\", \"results/CNN_02/loss_history/loss_history_2100.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_02 = ModelFactory.CNN_02()\n",
    "model_cnn_02.load_state_dict( torch.load('results/CNN_02/model/epoch_2100.pth'))\n",
    "calculate_stats_on_test_data(model_cnn_02, NoiseTypeEnum.EOG, cnn=True)\n",
    "calculate_stats_on_test_data(model_cnn_02, NoiseTypeEnum.EMG, cnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_prediction(model_cnn_02, combined, clean, cnn=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_loss_history(\"CNN 03\", \"results/CNN_03/loss_history/loss_history_1400.pickle\", skip=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn_03 = ModelFactory.CNN_03()\n",
    "model_cnn_03.load_state_dict( torch.load('results/CNN_03/model/epoch_900.pth'))\n",
    "calculate_stats_on_test_data(model_cnn_03, NoiseTypeEnum.EOG, cnn=True)\n",
    "calculate_stats_on_test_data(model_cnn_03, NoiseTypeEnum.EMG, cnn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_prediction(model_cnn_03, combined, clean, cnn=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
